{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zVycoJPTmk70"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense,Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkaQ3ylgoW0x"
   },
   "source": [
    "Step 2 : Dataset Definition <br>\n",
    "This is the dataset where each tuple consists of a simple English phrase and its French translation. This is a small toy dataset for the purpose of demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yyltR5XzpkJt"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"hello\", \"bonjour\"),\n",
    "    (\"how are you\", \"comment ça va\"),\n",
    "    (\"thank you\", \"merci\"),\n",
    "    (\"good morning\", \"bonjour\"),\n",
    "    (\"good night\", \"bonne nuit\"),\n",
    "    (\"see you later\", \"à plus tard\"),\n",
    "    (\"I love you\",\"je t'aime\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UN2RZRYEqGze"
   },
   "source": [
    "Step 3: Text Preparation\n",
    "\n",
    "zip(*data): Separates the data tuples into two separate lists: one for input_texts (English) and one for target_texts (French)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ks4ABkN1puM6"
   },
   "outputs": [],
   "source": [
    "input_texts, target_texts = zip(*data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQluuzYuqqFU"
   },
   "source": [
    "Step 4: Tokenization\n",
    "\n",
    "Tokenizer(): Creates a tokenizer that will convert text into sequences of integers. fit_on_texts(): This method creates a vocabulary from the input_texts and target_texts and assigns a unique integer to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B-a5Jg9zqoGo"
   },
   "outputs": [],
   "source": [
    "input_tokenizer=Tokenizer()\n",
    "target_tokenizer=Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "target_tokenizer.fit_on_texts(target_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf90HwIsr94C"
   },
   "source": [
    "texts_to_sequences(): Converts each text (sentence) into a sequence of integers. Each word in the text is\n",
    "\n",
    "replaced by its corresponding integer from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AhQw0lSwqwgn"
   },
   "outputs": [],
   "source": [
    "input_sequences=input_tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences=target_tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Wk1HeAjsXQg"
   },
   "source": [
    "Step 5: Vocabulary and Sequence Length Calculation\n",
    "\n",
    "word_index: This dictionary holds the integer mappings for each word. We add 1 to account for the 0-based Indexing of sequences. input_vocab_size and target_vocab_size: Store the size of the vocabulary for the input and target languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qK97xOLBr9Ua"
   },
   "outputs": [],
   "source": [
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index)+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q18cmQjetipr"
   },
   "source": [
    "max_input_len and max_target_len: Store the maximum length of sequences in the input and target languages, respectively. This helps with padding the sequences to a uniform length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fVHpE2sbsr83"
   },
   "outputs": [],
   "source": [
    "max_input_len = max(len(seq) for seq in input_sequences)\n",
    "max_target_len = max(len(seq) for seq in target_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Qxe3QOpuXMQ"
   },
   "source": [
    "Step 6: Padding Sequences\n",
    "pad_sequences pads each sequence to ensure that all seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "C6fIJW3NuwrK"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = pad_sequences(input_sequences, maxlen= max_input_len, padding=\"post\")\n",
    "decoder_input_data= pad_sequences(target_sequences, maxlen=max_target_len,padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2EOV_QesSxZ"
   },
   "source": [
    "Step 7: One-Hot Encoding Target Sequences\n",
    "\n",
    "np.zeros(): Creates a zero matrix where each row corresponds to a sentence and each column corresponds to a time step\n",
    "in the sequence. The depth corresponds to the size of the vocabulary (for one-hot encoding). for loop: Loops over the\n",
    "target sequences and creates one-hot encoded vectors where only the index corresponding to the word is 1. The shift by\n",
    "one ensures that the target data starts predicting from the secondword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MC6sWD8QsB61"
   },
   "outputs": [],
   "source": [
    "decoder_target_data = np.zeros((len(target_texts), max_target_len, target_vocab_size), dtype=\"float32\")\n",
    "\n",
    "for i, seq in enumerate(target_sequences):\n",
    "    for t, word in enumerate(seq):\n",
    "        if t > 0:\n",
    "            # Target sequence shifted by one\n",
    "            decoder_target_data[i, t-1,word]=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNFfuMSovOoY"
   },
   "source": [
    "Step 8: Splitting the Data\n",
    "\n",
    "train_test_split(): Splits the input data (encoder and decoder inputs) and target data into trining and testing sets. test_size=0.2 means 20% of the data is used for testing and 80% data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y_uMqg0ltFHW"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, decoder_input_train, decoder_input_test = train_test_split(\n",
    "    encoder_input_data, decoder_target_data, decoder_input_data, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFhXmqW1xR4u"
   },
   "source": [
    "Step 9: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TgdnkDBEwL_d"
   },
   "outputs": [],
   "source": [
    "# embedding_dim 128 # Or any other value you'd like, typically 50, 100, or 100\n",
    "\n",
    "# Define hyperparameters\n",
    "\n",
    "latent_dim=128 # Number of units in LSTM\n",
    "embedding_dim= 128 # Size of word embedding\n",
    "\n",
    "# You can adjust the values based on your model's requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjDZH4Eex8tx"
   },
   "source": [
    "Input(shape=(max_input_len,)): Defines the input shape for the encoder (input sentence length). Embedding(): Maps the input word indices to dense vectors of size embedding_dim. LSTM(): The LSTM layer processes the Input embeddings and returns two things: the final hidden state (state_h) and cell state (state_c). These states will pased to the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZefeL6WNxncD"
   },
   "outputs": [],
   "source": [
    "# Define encoder inputs and embedding\n",
    "encoder_inputs = Input(shape=(max_input_len,))\n",
    "encoder_embedding = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# Define LSTM layer with latent_dim units and return state\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "# Get encoder outputs and states\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPV6vFPOz1Vd"
   },
   "source": [
    "Similar to the encoder, the decoder also has an embedding layer followed by an LSTM. The LSTM receives the encoder's final states (state_h, state_c) as initial states for the decoding process. return_sequences=True ensures that the decoder produces a sequence of outputs rather than just the last output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6QBcJfPVyWoK"
   },
   "outputs": [],
   "source": [
    "# Define decoder inputs and embedding\n",
    "decoder_inputs = Input(shape=(max_target_len,))\n",
    "decoder_embedding = Embedding(target_vocab_size, embedding_dim)(decoder_inputs)\n",
    "\n",
    "# Define LSTM layer for the decoder with return_sequences=True to return the full sequence\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "# Get decoder outputs and states, initializing with the encoder's hidden and cell states\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h,state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kcpxx5rN0tZ8"
   },
   "source": [
    "Dense Layer\n",
    "\n",
    "Dense(): A fully connected layer that outputs a probability distribution over the target vocabulary (for each word in the sequence). softmax: Ensures the output is a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qHLs6YsRz60D"
   },
   "outputs": [],
   "source": [
    "# Define a Dense layer with softmax activation to produce probabilities for each word in the target vocabulary\n",
    "decoder_dense = Dense(target_vocab_size, activation=\"softmax\")\n",
    "\n",
    "# Apply the dense layer to the decoder outputs\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlAahseY19fx"
   },
   "source": [
    "First -> encoder\n",
    "then encoder -> decorator\n",
    "decorator output -> dense layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ST6nz_-2WFZ"
   },
   "source": [
    "Step 10: Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FjE6Mp9I18tL"
   },
   "outputs": [],
   "source": [
    "# Define the full model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4oDWNrr-2nSn",
    "outputId": "d1148ad9-c438-4b6b-d953-a261c7b6c735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.0667 - loss: 0.8287 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1333 - loss: 0.8238 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2667 - loss: 0.8187 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3333 - loss: 0.8136 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.8083 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.3333 - loss: 0.8029 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2667 - loss: 0.7972 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2667 - loss: 0.7911 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2667 - loss: 0.7848 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2667 - loss: 0.7780 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2667 - loss: 0.7708 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2667 - loss: 0.7630 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2667 - loss: 0.7546 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2667 - loss: 0.7457 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2667 - loss: 0.7359 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2667 - loss: 0.7254 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2667 - loss: 0.7141 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2667 - loss: 0.7018 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2667 - loss: 0.6886 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2667 - loss: 0.6743 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2667 - loss: 0.6590 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2667 - loss: 0.6427 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2667 - loss: 0.6257 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2667 - loss: 0.6083 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2667 - loss: 0.5909 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2667 - loss: 0.5742 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2667 - loss: 0.5589 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.2667 - loss: 0.5453 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1333 - loss: 0.5341 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1333 - loss: 0.5250 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1333 - loss: 0.5179 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.1333 - loss: 0.5126 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1333 - loss: 0.5087 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1333 - loss: 0.5063 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1333 - loss: 0.5051 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1333 - loss: 0.5050 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1333 - loss: 0.5054 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1333 - loss: 0.5059 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.1333 - loss: 0.5063 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2000 - loss: 0.5067 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1333 - loss: 0.5073 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1333 - loss: 0.5081 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1333 - loss: 0.5092 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1333 - loss: 0.5103 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1333 - loss: 0.5111 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1333 - loss: 0.5112 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1333 - loss: 0.5105 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.1333 - loss: 0.5092 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.1333 - loss: 0.5077 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1333 - loss: 0.5062 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1333 - loss: 0.5048 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.1333 - loss: 0.5034 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.1333 - loss: 0.5017 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1333 - loss: 0.4995 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1333 - loss: 0.4968 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.1333 - loss: 0.4938 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.1333 - loss: 0.4907 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.1333 - loss: 0.4877 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.1333 - loss: 0.4846 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.1333 - loss: 0.4813 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1333 - loss: 0.4779 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1333 - loss: 0.4741 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.1333 - loss: 0.4700 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.1333 - loss: 0.4658 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.1333 - loss: 0.4615 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1333 - loss: 0.4573 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.1333 - loss: 0.4533 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1333 - loss: 0.4494 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.1333 - loss: 0.4454 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.1333 - loss: 0.4414 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.1333 - loss: 0.4371 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.1333 - loss: 0.4325 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1333 - loss: 0.4278 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.2000 - loss: 0.4239 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2000 - loss: 0.4210 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2000 - loss: 0.4186 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2000 - loss: 0.4159 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2000 - loss: 0.4124 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2000 - loss: 0.4081 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2000 - loss: 0.4031 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2000 - loss: 0.3980 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2000 - loss: 0.3932 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.2667 - loss: 0.3890 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.2667 - loss: 0.3855 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.2667 - loss: 0.3825 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.2667 - loss: 0.3796 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2667 - loss: 0.3769 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.3333 - loss: 0.3742 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3333 - loss: 0.3716 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3333 - loss: 0.3693 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.3333 - loss: 0.3673 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3333 - loss: 0.3655 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3333 - loss: 0.3636 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.3333 - loss: 0.3612 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3333 - loss: 0.3579 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.3333 - loss: 0.3541 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.3333 - loss: 0.3501 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3333 - loss: 0.3467 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.3333 - loss: 0.3439 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.3333 - loss: 0.3410 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7baddff66710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([X_train, decoder_input_train], y_train, batch_size=32, epochs=100, validation_data=([X_test, decoder_input_test],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvY229Pb26XN",
    "outputId": "7bd13c25-180a-480e-d910-9dcff7c0250a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "Translated sentence: nuit \n"
     ]
    }
   ],
   "source": [
    "# Purpose of Inference Models\n",
    "# After the model has been trained, we need to define the inference process to generate translations.\n",
    "\n",
    "# In the training process, both the encoder and decoder receive complete sequences.\n",
    "# However, during inference (prediction), we only have the input sentence,\n",
    "# and the decoder must generate the output word by word, one step at a time.\n",
    "\n",
    "# Thus, we create two separate models for inference:\n",
    "# Encoder model: Converts the input sentence into internal states (hidden and cell states)\n",
    "# that are passed to the decoder.\n",
    "# Decoder model: Takes the encoder's internal states and generates the output sequence word by word.\n",
    "\n",
    "# Define inference models for translation\n",
    "\n",
    "# Encoder model\n",
    "encoder_model=Model(encoder_inputs,[state_h,state_c])\n",
    "\n",
    "# Purpose: The encoder processes the input sequence and outputs its final internal states\n",
    "# (hidden state state_h and cell state state_c).\n",
    "# These states will be passed to the decoder during inference.\n",
    "# encoder_inputs: The input sequence for the encoder (which is padded).\n",
    "# [state_h, state_c]: The encoder's final states that the decoder will use to start\n",
    "# generating the output sequence.\n",
    "\n",
    "# Decoder model\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "\n",
    "# # decoder_state_input_h and decoder_state_input_c: Inputs to the decoder.\n",
    "# These are the hidden state (state_h) and cell state (state_c)\n",
    "# that were produced by the encoder.\n",
    "# In inference, we don't have these states at the beginning,\n",
    "# so they are taken as inputs for the decoder.\n",
    "\n",
    "decoder_lstm_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_embedding, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "decoder_outputs= decoder_dense(decoder_lstm_outputs)\n",
    "decoder_model=Model(\n",
    "    [decoder_inputs, decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs, decoder_state_h, decoder_state_c]\n",
    ")\n",
    "\n",
    "# The decoder LSTM takes in the current word (embedding using the decoder_embedding layer)\n",
    "# along with the hidden and the cell states (decoder_state_input_h and decoder_state_input_c)\n",
    "# as initial states\n",
    "# decoder_lstm outputs: The lstm outputs fot the current time stamp\n",
    "\n",
    "#Function to decode a sequence using the trained model\n",
    "#The function takes an input sequence (from a source language, for example)\n",
    "#and uses an encoder-decoder model to generate a translated sequence (target language).\n",
    "# It performs this in an iterative manner, predicting one word at a time,\n",
    "#until it either predicts the end-of-sequence token or reaches a specified maximum length.\n",
    "\n",
    "\n",
    "# Function to decode a sequence using the trained model\n",
    "# The function takes an input sequence (from a source language, for example)\n",
    "# and uses an encoder-decoder model to generate a translated sequence (target language).\n",
    "#\n",
    "# It performs this in an iterative manner, predicting one word at a time,\n",
    "# until it either predicts the end-of-sequence token or reaches a specified maximum length.\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Get the states from the encoder model\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "# input_seq : This is the sequence that you want to translate\n",
    "# The encoder_model processes the input sequence and returns the states_value\n",
    "# hidden and cell states) that represents the context learned from the input sequence\n",
    "# These states are used as the initial state for the decoder.\n",
    "\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "# target_seq: This starts as an array of zeros because at the beginning.\n",
    "# There is no input to the decoder. As the decoder predicts words,\n",
    "# this array will hold the index of the word generated at the previous step.\n",
    "\n",
    "    stop_condition=False\n",
    "    decoded_sentence=\"\"\n",
    "\n",
    "# decoded_sentence: An empty string that will hold the geerated translation.\n",
    "# stop_conditions: A flag to indicate when the decoding process should stop.\n",
    "# decoded_sentence: This string will store the predicted translation.\n",
    "    while not stop_condition:\n",
    "        # The loop continues until the translation is complete\n",
    "        # (i.e., when the decoder generates an end token or exceeds the allowed length).\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # decoder_model uses the current target sequence (target_seq)\n",
    "        # and the encoder's final states (states_value) to predict the next word.\n",
    "        # output_tokens: The predicted probabilities of the next word.\n",
    "        # h, c: The updated hidden and cell states. These states are passed to the next iteration to ensure continuity.\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_tokenizer.index_word.get(sampled_token_index, \"\")\n",
    "        #output_tokens [0, -1, :]:\n",
    "\n",
    "        #The output_tokens array contains the predicted probabilities for each possible word in the vocal\n",
    "        #The shape of output_tokens is typically (batch_size, sequence_length, vocabulary_size).\n",
    "        #In this case, batch_size is 1 because we are decoding one sentence.\n",
    "        #sequence_length is 1 because at each time step, only one word is generated.\n",
    "        #vocabulary_size is the number of possible words in the target vocabulary.\n",
    "        #output tokens [0, -1, :] selects the predicted probabilities of words at the current time step\n",
    "        #Illustartion : Suppose the vocabulary has 5 words:{0:'hello',1:'world',2:'how',3:'are',4:'you'}\n",
    "        # The ouput_tokens might look something like this\n",
    "        # output_tokens[0,-1,:]=[0.1,0.6, 0.05, 0.15, 0.1]\n",
    "        # sampled_token_index = np.argmax(output_tokens[0, -1, :]):\n",
    "\n",
    "        # np.argmax() finds the index of the highest probability from the output_tokens array.\n",
    "        # In this case, it will select the index 1 because the highest probablity (0.6)\n",
    "        # corresponds to the word 'world'\n",
    "        # putting it all together\n",
    "\n",
    "        # After running np.argmax(), the most likely word's index (1 in thi case) is selected.\n",
    "        # This index is then used to retrive the corresponding word('world' in this case)\n",
    "        # From the tokenizer's dictionary\n",
    "\n",
    "        decoded_sentence += sampled_word +\" \"\n",
    "\n",
    "            #The predicted word is appended to the decoded_sentence string.\n",
    "        if sampled_word == \"<end>\" or len(decoded_sentence) > max_target_len:\n",
    "          stop_condition = True\n",
    "        #The decoding process stops when the <end> token is predicted,\n",
    "        #or if the sentence exceeds the maximum allowed length (max_target_len).\n",
    "        #Update the target sequence for the next iteration:\n",
    "\n",
    "        target_seq= np.zeros((1, 1))\n",
    "        #This line creates a 2D NumPy array filled with zeros, with the shape (1, 1).\n",
    "        # by the decoder in the previous step) to the target_seq.\n",
    "        # The value is placed at position [0,0] because it's a 1X1 array, and [0, 0]\n",
    "        # refers to the only element in that array.\n",
    "\n",
    "        # sampled_token_index=1(from the privious word prediction step).\n",
    "        # After this assignment, the target_seq will look like this:\n",
    "        # target_seq[0,0]=1\n",
    "        # Result : target_seq =[[1.]]\n",
    "        #Purpose:\n",
    "        #The target_seq is used as the input for the decoder at the next time step.\n",
    "        #At each decoding step, the decoder needs to be fed the token (or word) predicted\n",
    "        #in the previous time step. So, this array is updated with the index of the\n",
    "        #predicted word (sampled_token_index) and then passed to the decoder for the next prediction.\n",
    "\n",
    "        states_value = [h, c]\n",
    "        #The updated hidden and cell states (h and c) are passed back into the decoder\n",
    "        #to maintain the flow of information across time steps.\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# translate(sentence): This function translates a given sentence.\n",
    "\n",
    "# input_tokenizer.texts_to_sequences([sentence]): Converts the input sentence into a sequence of tokens.\n",
    "# pad_sequences(): Pads the input sequence to the maximum length (since the model expects inputs to be of uniform length).\n",
    "# decode_sequence(): Calls the decoding function to generate the translation for the given input sequence.\n",
    "\n",
    "# Translate a sentence\n",
    "def translate(sentence):\n",
    "\n",
    "    sequence = input_tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "    # sentence: This is the input sentence you want to translate (from the source language).\n",
    "    # input_tokenizer.texts_to_sequences([sentence]):\n",
    "    # input_tokenizer is a tokenizer that has already been trained on the source language.\n",
    "    # It contains a vocabulary mapping words to numerical indices (tokens).\n",
    "    # texts_to_sequences converts the sentence (a list of words) into a list of numerical indices\n",
    "    # representing the words in the sentence.\n",
    "    # For example, if the input sentence is \"hello world\" and the tokenizer maps 'hello' to 1\n",
    "    # and 'world' to 2, the resulting sequence will be [1, 2].\n",
    "\n",
    "    sequence = pad_sequences(sequence, maxlen=max_input_len, padding=\"post\")\n",
    "\n",
    "    # pad_sequences():\n",
    "    # This function ensures that all sequences (inputs) are of the same length.\n",
    "    # Since neural networks often require fixed-length input, the input sequence is either\n",
    "    # truncated (if too long) or padded with zeros (if too short) to match the required length.\n",
    "    # maxlen=max_input_len: The maximum length that the input sequence should be.\n",
    "    # This is a predefined length based on how the model was trained.\n",
    "    # padding=\"post\": If padding is needed, zeros will be added to the end (or \"post\") of the sequence.\n",
    "\n",
    "    # Result: sequence = [[1, 2, 0, 0, 0]] (example)\n",
    "\n",
    "    translation = decode_sequence(sequence)\n",
    "\n",
    "    # This function is the core of the translation process. It takes the processed input sequence (now padded).\n",
    "    # Inside the decode_sequence function, the model predicts one word at a time\n",
    "    # (as explained earlier) until it reaches an end token (<end>) or a maximum sentence length.\n",
    "\n",
    "    return translation\n",
    "\n",
    "# Example usage:\n",
    "# print(translate(\"hello world\"))\n",
    "translated_sentence = translate(\"hello\")\n",
    "print(\"Translated sentence:\", translated_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEeHKsN1FTB4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
